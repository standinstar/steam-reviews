{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "714ed387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import re\n",
    "from os.path import join\n",
    "# utilities\n",
    "import pickle\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#ekphrasis\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "#gensim\n",
    "import gensim\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5bc9a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import langid\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ff00346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "df1 = pd.read_csv('D:/data2.csv',encoding=DATASET_ENCODING)\n",
    "df2 = pd.read_csv('D:/data4.csv',encoding=DATASET_ENCODING)\n",
    "df3 = pd.read_csv('D:/data5.csv',encoding=DATASET_ENCODING)\n",
    "df4 = pd.read_csv('D:/data6.csv',encoding=DATASET_ENCODING)\n",
    "df5 = pd.read_csv('D:/data7.csv',encoding=DATASET_ENCODING)\n",
    "df6 = pd.read_csv('D:/data8.csv',encoding=DATASET_ENCODING)\n",
    "df7 = pd.read_csv('D:/data9.csv',encoding=DATASET_ENCODING)\n",
    "df8 = pd.read_csv('D:/data10.csv',encoding=DATASET_ENCODING)\n",
    "df9 = pd.read_csv('D:/data11.csv',encoding=DATASET_ENCODING)\n",
    "df10 = pd.read_csv('D:/data12.csv',encoding=DATASET_ENCODING)\n",
    "df11 = pd.read_csv('D:/data13.csv',encoding=DATASET_ENCODING)\n",
    "df12 = pd.read_csv('D:/data14.csv',encoding=DATASET_ENCODING)\n",
    "df13 = pd.read_csv('D:/data15.csv',encoding=DATASET_ENCODING)\n",
    "df14 = pd.read_csv('D:/data16.csv',encoding=DATASET_ENCODING)\n",
    "df15 = pd.read_csv('D:/data17.csv',encoding=DATASET_ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "554c870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('D:/data18.csv',encoding=DATASET_ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5f72f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = df14.columns\n",
    "df2.columns = df14.columns\n",
    "df = pd.concat([df1,df2,df12,df13,df14,df15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bbf88853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>country</th>\n",
       "      <th>time_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>value</th>\n",
       "      <th>fun</th>\n",
       "      <th>reviews</th>\n",
       "      <th>game</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>Unnamed: 39</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "      <th>Unnamed: 41</th>\n",
       "      <th>Unnamed: 42</th>\n",
       "      <th>Unnamed: 43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119833...</td>\n",
       "      <td>Other</td>\n",
       "      <td>10</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ulan salak gibi gittiniz harita seÃ§meyi kaldÄ...</td>\n",
       "      <td>https://steamcommunity.com/app/578080</td>\n",
       "      <td>12 February, 2021</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119833...</td>\n",
       "      <td>Other</td>\n",
       "      <td>9</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>TÃ¼rkÃ§e dil desteÄi olsa keÅke onun dÄ±ÅÄ±...</td>\n",
       "      <td>https://steamcommunity.com/app/1145360</td>\n",
       "      <td>8 December, 2020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119833...</td>\n",
       "      <td>Other</td>\n",
       "      <td>8</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Para basmadan en ufak zevk alamazsÄ±nÄ±z. Size...</td>\n",
       "      <td>https://steamcommunity.com/app/236390</td>\n",
       "      <td>26 November, 2020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119833...</td>\n",
       "      <td>Other</td>\n",
       "      <td>7</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>MuhteÅem grafikleri, sinematik sunumu, ÅarkÄ...</td>\n",
       "      <td>https://steamcommunity.com/app/261570</td>\n",
       "      <td>26 November, 2020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119833...</td>\n",
       "      <td>Other</td>\n",
       "      <td>6</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Hikayesi, mekanikleri Ã§Ä±ktÄ±ÄÄ± yÄ±la gÃ¶re...</td>\n",
       "      <td>https://steamcommunity.com/app/302510</td>\n",
       "      <td>26 November, 2020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23955</th>\n",
       "      <td>2395</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119802...</td>\n",
       "      <td>Other</td>\n",
       "      <td>5</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10/10\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>https://steamcommunity.com/app/581320</td>\n",
       "      <td>1 July, 2019</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23956</th>\n",
       "      <td>2395</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119802...</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10/10\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>https://steamcommunity.com/app/755790</td>\n",
       "      <td>8 December, 2018</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23957</th>\n",
       "      <td>2395</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119802...</td>\n",
       "      <td>Other</td>\n",
       "      <td>3</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10/10\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>https://steamcommunity.com/app/675010</td>\n",
       "      <td>22 November, 2018</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23958</th>\n",
       "      <td>2395</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119802...</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9,5/10\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>https://steamcommunity.com/app/227300</td>\n",
       "      <td>6 September, 2018</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23959</th>\n",
       "      <td>2395</td>\n",
       "      <td>https://steamcommunity.com/profiles/7656119802...</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10/10\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>https://steamcommunity.com/app/262410</td>\n",
       "      <td>28 June, 2018</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23960 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               link country  \\\n",
       "0         1  https://steamcommunity.com/profiles/7656119833...   Other   \n",
       "1         1  https://steamcommunity.com/profiles/7656119833...   Other   \n",
       "2         1  https://steamcommunity.com/profiles/7656119833...   Other   \n",
       "3         1  https://steamcommunity.com/profiles/7656119833...   Other   \n",
       "4         1  https://steamcommunity.com/profiles/7656119833...   Other   \n",
       "...     ...                                                ...     ...   \n",
       "23955  2395  https://steamcommunity.com/profiles/7656119802...   Other   \n",
       "23956  2395  https://steamcommunity.com/profiles/7656119802...   Other   \n",
       "23957  2395  https://steamcommunity.com/profiles/7656119802...   Other   \n",
       "23958  2395  https://steamcommunity.com/profiles/7656119802...   Other   \n",
       "23959  2395  https://steamcommunity.com/profiles/7656119802...   Other   \n",
       "\n",
       "       time_id        recommend  value  fun  \\\n",
       "0           10  Not Recommended      0    0   \n",
       "1            9      Recommended      2    0   \n",
       "2            8  Not Recommended      3    0   \n",
       "3            7      Recommended     21    0   \n",
       "4            6  Not Recommended      6    0   \n",
       "...        ...              ...    ...  ...   \n",
       "23955        5      Recommended      0    0   \n",
       "23956        4      Recommended      0    1   \n",
       "23957        3      Recommended      0    0   \n",
       "23958        2      Recommended      3    0   \n",
       "23959        1      Recommended      0    0   \n",
       "\n",
       "                                                 reviews  \\\n",
       "0      Ulan salak gibi gittiniz harita seÃ§meyi kaldÄ...   \n",
       "1      TÃ¼rkÃ§e dil desteÄi olsa keÅke onun dÄ±ÅÄ±...   \n",
       "2      Para basmadan en ufak zevk alamazsÄ±nÄ±z. Size...   \n",
       "3      MuhteÅem grafikleri, sinematik sunumu, ÅarkÄ...   \n",
       "4      Hikayesi, mekanikleri Ã§Ä±ktÄ±ÄÄ± yÄ±la gÃ¶re...   \n",
       "...                                                  ...   \n",
       "23955                              10/10\\t\\t\\t\\t\\t\\t\\t\\t   \n",
       "23956                              10/10\\t\\t\\t\\t\\t\\t\\t\\t   \n",
       "23957                              10/10\\t\\t\\t\\t\\t\\t\\t\\t   \n",
       "23958                             9,5/10\\t\\t\\t\\t\\t\\t\\t\\t   \n",
       "23959                              10/10\\t\\t\\t\\t\\t\\t\\t\\t   \n",
       "\n",
       "                                         game               date  ...  \\\n",
       "0       https://steamcommunity.com/app/578080  12 February, 2021  ...   \n",
       "1      https://steamcommunity.com/app/1145360   8 December, 2020  ...   \n",
       "2       https://steamcommunity.com/app/236390  26 November, 2020  ...   \n",
       "3       https://steamcommunity.com/app/261570  26 November, 2020  ...   \n",
       "4       https://steamcommunity.com/app/302510  26 November, 2020  ...   \n",
       "...                                       ...                ...  ...   \n",
       "23955   https://steamcommunity.com/app/581320       1 July, 2019  ...   \n",
       "23956   https://steamcommunity.com/app/755790   8 December, 2018  ...   \n",
       "23957   https://steamcommunity.com/app/675010  22 November, 2018  ...   \n",
       "23958   https://steamcommunity.com/app/227300  6 September, 2018  ...   \n",
       "23959   https://steamcommunity.com/app/262410      28 June, 2018  ...   \n",
       "\n",
       "      Unnamed: 34 Unnamed: 35 Unnamed: 36 Unnamed: 37 Unnamed: 38 Unnamed: 39  \\\n",
       "0             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "23955         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "23956         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "23957         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "23958         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "23959         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      Unnamed: 40 Unnamed: 41 Unnamed: 42 Unnamed: 43  \n",
       "0             NaN         NaN         NaN         NaN  \n",
       "1             NaN         NaN         NaN         NaN  \n",
       "2             NaN         NaN         NaN         NaN  \n",
       "3             NaN         NaN         NaN         NaN  \n",
       "4             NaN         NaN         NaN         NaN  \n",
       "...           ...         ...         ...         ...  \n",
       "23955         NaN         NaN         NaN         NaN  \n",
       "23956         NaN         NaN         NaN         NaN  \n",
       "23957         NaN         NaN         NaN         NaN  \n",
       "23958         NaN         NaN         NaN         NaN  \n",
       "23959         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[23960 rows x 44 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "02bfc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['english'] = df['reviews'].apply(lambda x: langid.classify(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a640c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['english'] == 'en']\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "27dbfd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['english'] = test['reviews'].apply(lambda x: langid.classify(x)[0])\n",
    "test = test[test['english'] == 'en']\n",
    "test = test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5b0b18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df[['id','value','reviews','time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9c690c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['ID','value','reviews','time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8b17c25f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user = data.groupby('id').count().reset_index()\n",
    "user = user[user['value']==10]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9b170208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>value</th>\n",
       "      <th>reviews</th>\n",
       "      <th>time_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>kox\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Fajna gra polecan\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Fajna gra polecan\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>i dont think i need to review, this game made ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>its a mafia game.... and it comes from 2K... s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>its my favorite up to date\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>freaking addicting!!!!\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>could better optimized, but the content and st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  value                                            reviews  time_id\n",
       "0     1      0                                kox\\t\\t\\t\\t\\t\\t\\t\\t       10\n",
       "1     1      0                                 Ok\\t\\t\\t\\t\\t\\t\\t\\t        9\n",
       "2     1      0                  Fajna gra polecan\\t\\t\\t\\t\\t\\t\\t\\t        8\n",
       "3     1      0                  Fajna gra polecan\\t\\t\\t\\t\\t\\t\\t\\t        7\n",
       "4     1      0                                 Ok\\t\\t\\t\\t\\t\\t\\t\\t        6\n",
       "..   ..    ...                                                ...      ...\n",
       "235  85      0  i dont think i need to review, this game made ...        5\n",
       "236  85      0  its a mafia game.... and it comes from 2K... s...        4\n",
       "237  85      0         its my favorite up to date\\t\\t\\t\\t\\t\\t\\t\\t        3\n",
       "238  85      0             freaking addicting!!!!\\t\\t\\t\\t\\t\\t\\t\\t        2\n",
       "239  85      1  could better optimized, but the content and st...        1\n",
       "\n",
       "[240 rows x 4 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user = test.groupby('ID').count().reset_index()\n",
    "test_user = test_user[test_user['value']==10]['ID']\n",
    "test = pd.merge(test[['ID','value','reviews','time_id']],test_user,on = 'ID')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e7feb321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>reviews</th>\n",
       "      <th>time_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;3\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>so good!\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>good\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>good\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>good\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>2055</td>\n",
       "      <td>1</td>\n",
       "      <td>Overall the game is very fun, it remind me of ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>2055</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Comedy of the Year. 10/10\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>2055</td>\n",
       "      <td>0</td>\n",
       "      <td>Great\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>2055</td>\n",
       "      <td>0</td>\n",
       "      <td>Okay I just wanna say that this game is a good...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>2055</td>\n",
       "      <td>0</td>\n",
       "      <td>Its a small clip made by the community and its...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  value                                            reviews  time_id\n",
       "0        2      0                                 <3\\t\\t\\t\\t\\t\\t\\t\\t       10\n",
       "1        2      0                           so good!\\t\\t\\t\\t\\t\\t\\t\\t        9\n",
       "2        2      0                               good\\t\\t\\t\\t\\t\\t\\t\\t        8\n",
       "3        2      0                               good\\t\\t\\t\\t\\t\\t\\t\\t        7\n",
       "4        2      0                               good\\t\\t\\t\\t\\t\\t\\t\\t        6\n",
       "...    ...    ...                                                ...      ...\n",
       "5005  2055      1  Overall the game is very fun, it remind me of ...        5\n",
       "5006  2055      1     Best Comedy of the Year. 10/10\\t\\t\\t\\t\\t\\t\\t\\t        4\n",
       "5007  2055      0                              Great\\t\\t\\t\\t\\t\\t\\t\\t        3\n",
       "5008  2055      0  Okay I just wanna say that this game is a good...        2\n",
       "5009  2055      0  Its a small clip made by the community and its...        1\n",
       "\n",
       "[5010 rows x 4 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(df[['id','value','reviews','time_id']],user,on = 'id')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9b4ee280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "<allcaps> cant wait </allcaps> for the new season of <hashtag> twin peaks </hashtag> ＼(^o^)／ ! <repeated> <hashtag> david lynch </hashtag> <hashtag> tv series </hashtag> <happy>\n",
      "i saw the new <hashtag> john doe </hashtag> movie and it sucks <elongated> ! <repeated> <allcaps> waisted </allcaps> <money> . <repeated> <hashtag> bad movies </hashtag> <annoyed>\n",
      "<user> : can not wait for the <date> <hashtag> sentiment </hashtag> talks ! <allcaps> yay <elongated> </allcaps> ! <repeated> <laugh> <url>\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "        'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n",
    "\n",
    "sentences = [\n",
    "    \"CANT WAIT for the new season of #TwinPeaks ＼(^o^)／!!! #davidlynch #tvseries :)))\",\n",
    "    \"I saw the new #johndoe movie and it suuuuucks!!! WAISTED $10... #badmovies :/\",\n",
    "    \"@SentimentSymp:  can't wait for the Nov 9 #Sentiment talks!  YAAAAAAY !!! :-D http://sentimentsymposium.com/.\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    print(\" \".join(text_processor.pre_process_doc(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "32f7c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data\n",
    "data_set.loc[:,'reviews'] = data_set.loc[:,'reviews'].apply(lambda x: \" \".join(text_processor.pre_process_doc(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3cd6c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test\n",
    "test_set.loc[:,'reviews'] = test_set.loc[:,'reviews'].apply(lambda x: \" \".join(text_processor.pre_process_doc(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "74976e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fajna gra polecan'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.loc[3,'reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "42e33e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "28a14a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['len'] = data_set['reviews'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "96bc425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set = data_set[data_set['len']>10]\n",
    "# data_set = data_set.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3a93062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = []\n",
    "Vs = []\n",
    "As = []\n",
    "Ss = []\n",
    "Ones = []\n",
    "Twos = []\n",
    "Longs = []\n",
    "Ws = []\n",
    "for index,row in data_set.iterrows():\n",
    "    tag = nltk.pos_tag(word_tokenize(row['reviews']))\n",
    "    N = 0\n",
    "    V = 0\n",
    "    A = 0\n",
    "    S = 0\n",
    "    W = len(tag)\n",
    "    Long = 0\n",
    "    One = 0\n",
    "    Two = 0\n",
    "    for i in tag:\n",
    "        if len(i[0]) == 1 and i[0] not in \"~!@#$%^&*()_+-*/<>,.[]\\/\":\n",
    "            One = One + 1\n",
    "        elif len(i[0]) == 2:\n",
    "            Two = Two + 1\n",
    "        elif len(i[0]) > 2:\n",
    "            Long = Long + 1\n",
    "\n",
    "        if i[1] == 'NN' or i[1] == 'NNS':\n",
    "            N = N + 1\n",
    "        elif i[1] == '.':\n",
    "            S = S + 1\n",
    "        elif i[1] == 'VB' or i[1] == 'VBD' or i[1] == 'VBG' or i[1] == 'VBN' or i[1] == 'VBP' or i[1] == 'VBZ':\n",
    "            V = V + 1\n",
    "        elif i[1] == 'JJ' or i[1] == 'JJR' or i[1] == 'JJS':\n",
    "            A = A + 1\n",
    "    Ns.append(N)\n",
    "    Ss.append(S)\n",
    "    Vs.append(V)\n",
    "    As.append(A)\n",
    "    Ones.append(One)\n",
    "    Twos.append(Two)\n",
    "    Longs.append(Long)\n",
    "    Ws.append(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f18bdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "data_dict = {'Noun':Ns,'Verb':Vs,'Adjective':As,'One':Ones,'Two':Twos,\n",
    "             'Long':Longs,'Sentence':Ss,'Word':Ws,}\n",
    "X = DataFrame(data_dict)\n",
    "# X2 = df[['country','total_time','review_time']]\n",
    "# X['country'] = df['country']\n",
    "# X['review_time'] = df['review_time']\n",
    "# X = pd.get_dummies(X,columns = ['country'],drop_first = True)\n",
    "y = data_set.loc[:,'value'].reset_index()['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "eac98f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = []\n",
    "Vs = []\n",
    "As = []\n",
    "Ss = []\n",
    "Ones = []\n",
    "Twos = []\n",
    "Longs = []\n",
    "Ws = []\n",
    "for index,row in test_set.iterrows():\n",
    "    tag = nltk.pos_tag(word_tokenize(row['reviews']))\n",
    "    N = 0\n",
    "    V = 0\n",
    "    A = 0\n",
    "    S = 0\n",
    "    W = len(tag)\n",
    "    Long = 0\n",
    "    One = 0\n",
    "    Two = 0\n",
    "    for i in tag:\n",
    "        if len(i[0]) == 1 and i[0] not in \"~!@#$%^&*()_+-*/<>,.[]\\/\":\n",
    "            One = One + 1\n",
    "        elif len(i[0]) == 2:\n",
    "            Two = Two + 1\n",
    "        elif len(i[0]) > 2:\n",
    "            Long = Long + 1\n",
    "\n",
    "        if i[1] == 'NN' or i[1] == 'NNS':\n",
    "            N = N + 1\n",
    "        elif i[1] == '.':\n",
    "            S = S + 1\n",
    "        elif i[1] == 'VB' or i[1] == 'VBD' or i[1] == 'VBG' or i[1] == 'VBN' or i[1] == 'VBP' or i[1] == 'VBZ':\n",
    "            V = V + 1\n",
    "        elif i[1] == 'JJ' or i[1] == 'JJR' or i[1] == 'JJS':\n",
    "            A = A + 1\n",
    "    Ns.append(N)\n",
    "    Ss.append(S)\n",
    "    Vs.append(V)\n",
    "    As.append(A)\n",
    "    Ones.append(One)\n",
    "    Twos.append(Two)\n",
    "    Longs.append(Long)\n",
    "    Ws.append(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c90fb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "test_dict = {'Noun':Ns,'Verb':Vs,'Adjective':As,'One':Ones,'Two':Twos,\n",
    "             'Long':Longs,'Sentence':Ss,'Word':Ws,}\n",
    "X_test = DataFrame(test_dict)\n",
    "# X2 = df[['country','total_time','review_time']]\n",
    "# X['country'] = df['country']\n",
    "# X['review_time'] = df['review_time']\n",
    "# X = pd.get_dummies(X,columns = ['country'],drop_first = True)\n",
    "y_test = test_set.loc[:,'value'].reset_index()['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c8dbc864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &           0 \\\\\n",
      "\\midrule\n",
      "const     &    1.000000 \\\\\n",
      "Noun      &   26.203593 \\\\\n",
      "Verb      &   18.244511 \\\\\n",
      "Adjective &   11.069461 \\\\\n",
      "One       &    8.976846 \\\\\n",
      "Two       &   15.288623 \\\\\n",
      "Long      &   76.330938 \\\\\n",
      "Sentence  &    5.389621 \\\\\n",
      "Word      &  118.282236 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X.mean().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1a16d397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.065\n",
      "Model:                            OLS   Adj. R-squared:                  0.063\n",
      "Method:                 Least Squares   F-statistic:                     43.34\n",
      "Date:                Thu, 01 Sep 2022   Prob (F-statistic):           1.15e-67\n",
      "Time:                        20:54:11   Log-Likelihood:                -25937.\n",
      "No. Observations:                5010   AIC:                         5.189e+04\n",
      "Df Residuals:                    5001   BIC:                         5.195e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.3847      0.703      7.663      0.000       4.007       6.762\n",
      "Noun           0.4884      0.111      4.416      0.000       0.272       0.705\n",
      "Verb           0.2988      0.148      2.017      0.044       0.008       0.589\n",
      "Adjective      0.7124      0.159      4.486      0.000       0.401       1.024\n",
      "One            0.0735      0.081      0.905      0.366      -0.086       0.233\n",
      "Two           -0.1476      0.135     -1.092      0.275      -0.413       0.117\n",
      "Long           0.0544      0.069      0.783      0.434      -0.082       0.191\n",
      "Sentence       0.3696      0.177      2.090      0.037       0.023       0.716\n",
      "Word          -0.2070      0.071     -2.910      0.004      -0.346      -0.068\n",
      "==============================================================================\n",
      "Omnibus:                     8017.203   Durbin-Watson:                   1.550\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4921383.355\n",
      "Skew:                          10.400   Prob(JB):                         0.00\n",
      "Kurtosis:                     155.128   Cond. No.                         359.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "X=sm.add_constant(X) #添加常数项\n",
    "model=sm.OLS(y,X)\n",
    "results=model.fit()\n",
    "y_pred=pd.DataFrame(model.predict(results.params,X),\n",
    "                    columns=['pred'])\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "419a8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}    &      value       & \\textbf{  R-squared:         } &      0.065   \\\\\n",
      "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.064   \\\\\n",
      "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      43.49   \\\\\n",
      "\\textbf{Date:}             & Thu, 01 Sep 2022 & \\textbf{  Prob (F-statistic):} &   6.68e-68   \\\\\n",
      "\\textbf{Time:}             &     03:36:48     & \\textbf{  Log-Likelihood:    } &    -25937.   \\\\\n",
      "\\textbf{No. Observations:} &        5010      & \\textbf{  AIC:               } &  5.189e+04   \\\\\n",
      "\\textbf{Df Residuals:}     &        5001      & \\textbf{  BIC:               } &  5.195e+04   \\\\\n",
      "\\textbf{Df Model:}         &           8      & \\textbf{                     } &              \\\\\n",
      "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &              \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{const}     &       5.3709  &        0.702     &     7.646  &         0.000        &        3.994    &        6.748     \\\\\n",
      "\\textbf{Noun}      &       0.4987  &        0.110     &     4.553  &         0.000        &        0.284    &        0.713     \\\\\n",
      "\\textbf{Verb}      &       0.3352  &        0.150     &     2.240  &         0.025        &        0.042    &        0.629     \\\\\n",
      "\\textbf{Adjective} &       0.7689  &        0.158     &     4.879  &         0.000        &        0.460    &        1.078     \\\\\n",
      "\\textbf{One}       &       0.1128  &        0.085     &     1.327  &         0.185        &       -0.054    &        0.280     \\\\\n",
      "\\textbf{Two}       &      -0.1207  &        0.136     &    -0.888  &         0.374        &       -0.387    &        0.146     \\\\\n",
      "\\textbf{Long}      &       0.0744  &        0.073     &     1.018  &         0.309        &       -0.069    &        0.218     \\\\\n",
      "\\textbf{Sentence}  &       0.3996  &        0.180     &     2.225  &         0.026        &        0.048    &        0.752     \\\\\n",
      "\\textbf{Word}      &      -0.2405  &        0.075     &    -3.213  &         0.001        &       -0.387    &       -0.094     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Omnibus:}       & 8016.758 & \\textbf{  Durbin-Watson:     } &      1.550   \\\\\n",
      "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 4917349.178  \\\\\n",
      "\\textbf{Skew:}          &  10.399  & \\textbf{  Prob(JB):          } &       0.00   \\\\\n",
      "\\textbf{Kurtosis:}      & 155.064  & \\textbf{  Cond. No.          } &       356.   \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{OLS Regression Results}\n",
      "\\end{center}\n",
      "\n",
      "Notes: \\newline\n",
      " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "fa6bd62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of words\n",
    "word_list = []\n",
    "for i in data_set['reviews']:\n",
    "    word_list = word_list + i.split(' ')\n",
    "for i in test_set['reviews']:\n",
    "    word_list = word_list + i.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "59eb85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(word_list)\n",
    "token_index = {}\n",
    "count = 1\n",
    "for i in a:\n",
    "    token_index[str(i)] = count\n",
    "    count = count + 1\n",
    "token_index['<PLACE>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ce71452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rex\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  195981\n"
     ]
    }
   ],
   "source": [
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(data_set['reviews'])\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "X_train = vectoriser.transform(data_set['reviews'])\n",
    "test_train = vectoriser.transform(test_set['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "317f6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = data_set['value'].apply(lambda x:encode_y(x))\n",
    "y = data_set['value']\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y)\n",
    "\n",
    "y_pred_lexical = reg.predict(X_train)\n",
    "y_pred_lexical_test = reg.predict(test_train)\n",
    "# SVCmodel = LinearSVC()\n",
    "# SVCmodel.fit(X_train, y)\n",
    "# y_pred1 = SVCmodel.predict(X_train)\n",
    "# print(classification_report(y, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d8f29560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.38213355547073, 42.868558848300495)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rms1 = mean_squared_error(y, y_pred_lexical, squared=False)\n",
    "rms2 = mean_squared_error(y, y_pred, squared=False)\n",
    "rms1,rms2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8b6b8597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642466158542198"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, y_pred_lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e702b1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06484032825021502"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e385f2",
   "metadata": {},
   "source": [
    "### deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e41973a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = 'D:/CS918 Homework/glove/'\n",
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir=glove_dir + '6B.100.dat', mode='w')\n",
    "\n",
    "with open(glove_dir + 'glove.6B.100d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(float)\n",
    "        vectors.append(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8a025ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.carray(vectors[1:].reshape((400001, 100)), rootdir=glove_dir +'6B.100.dat', mode='w')\n",
    "vectors.flush()\n",
    "pickle.dump(words, open(glove_dir +'6B.100_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open(glove_dir +'6B.100_idx.pkl', 'wb'))\n",
    "\n",
    "\n",
    "vectors = bcolz.open(glove_dir +'6B.100.dat')[:]\n",
    "words = pickle.load(open(glove_dir +'6B.100_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(glove_dir +'6B.100_idx.pkl', 'rb'))\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0acddb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all the words using Counter Method\n",
    "from collections import Counter\n",
    "count_words = Counter(word_list)\n",
    "\n",
    "total_words = len(word_list)\n",
    "sorted_words = count_words.most_common(total_words)\n",
    "vocab_to_int = {w:(i+1) for i, (w,c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92ab305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_len = len(vocab_to_int)\n",
    "weights_matrix = np.zeros(((matrix_len+1), 100))\n",
    "words_found = 0\n",
    "\n",
    "for i, (w,c) in enumerate(sorted_words):\n",
    "    try: \n",
    "        weights_matrix[i+1] = glove[w]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i+1] = glove['<unk>']\n",
    "embedding_matrix = torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed3653b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.   1.   5.  76.8]\n"
     ]
    }
   ],
   "source": [
    "percentiles = np.array([2.5, 25, 50, 75, 97.5])\n",
    "ptiles_vers = np.percentile(y, percentiles)\n",
    " \n",
    "# Print the result\n",
    "print(ptiles_vers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f635a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_x(i):\n",
    "    b = []\n",
    "    for a in i.split():\n",
    "        if a in vocab_to_int.keys():\n",
    "            b.append(vocab_to_int[a])\n",
    "        else:\n",
    "            b.append(0)\n",
    "    return b\n",
    "\n",
    "def encode_y(a):\n",
    "    if a < 1:\n",
    "        return 0\n",
    "    elif a >= 1 and a < 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def pad_features(reviews_int, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "    '''\n",
    "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
    "    \n",
    "    for i, review in enumerate(reviews_int):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= seq_length:\n",
    "            zeroes = list(np.zeros(seq_length-review_len))\n",
    "            new = review+zeroes\n",
    "        elif review_len > seq_length:\n",
    "            new = review[0:seq_length]\n",
    "        \n",
    "        features[i,:] = np.array(new)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85459e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rex\\AppData\\Local\\Temp/ipykernel_14292/171984446.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_set['new_X'] = data_set['reviews'].apply(lambda x : encode_x(x))\n",
      "C:\\Users\\rex\\AppData\\Local\\Temp/ipykernel_14292/171984446.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_set['new_y'] = data_set['value'].apply(lambda x : encode_y(x))\n"
     ]
    }
   ],
   "source": [
    "data_set['new_X'] = data_set['reviews'].apply(lambda x : encode_x(x))\n",
    "data_set['new_y'] = data_set['value'].apply(lambda x : encode_y(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2329093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = pad_features(data_set['new_X'],50)\n",
    "new_y = data_set['value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca255d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train.values))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test.values))\n",
    "predict_data = TensorDataset(torch.from_numpy(new_X), torch.from_numpy(new_y.values))\n",
    "# dataloaders\n",
    "batch_size = 10\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last = True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last = True)\n",
    "test_loader = DataLoader(predict_data, shuffle=False, batch_size=batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09e03e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size, embedding_matrix,embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim       \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
    "        self.embedding.requires_grad = False\n",
    "        self.emebdding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers \n",
    "                            ,dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # linear layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "\n",
    "    def attention_net(self, x, query, mask=None): \n",
    "\n",
    "        d_k = query.size(-1)     # d_k is the dimension of query\n",
    "        # query:[batch, seq_len, hidden_dim], x.t:[batch, hidden_dim, seq_len]\n",
    "        # scores: [batch, seq_len, seq_len]\n",
    "        scores = torch.matmul(query, x.transpose(1, 2)) / math.sqrt(d_k)  \n",
    "        alpha_n = F.softmax(scores, dim=-1) \n",
    "        # [batch, seq_len, seq_len]·[batch,seq_len, hidden_dim] = [batch,seq_len,hidden_dim] -> [batch, hidden_dim]\n",
    "        context = torch.matmul(scores, x).sum(1)\n",
    "\n",
    "        return context, alpha_n\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        embeds = self.dropout(embeds)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        #attention\n",
    "        query = self.dropout(lstm_out)\n",
    "        attn_output, alpha_n = self.attention_net(lstm_out, query)\n",
    "        # fully-connected layer       \n",
    "        tag_space = self.fc(attn_output)\n",
    "        # softmax function\n",
    "#         tag_scores = F.log_softmax(tag_space,dim = 1)\n",
    "        tag_scores = F.relu(tag_space)\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return tag_scores, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25ef1b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Step: 100... Loss: 24.529444... Val Loss: 2080.066504\n",
      "Epoch: 1/100... Step: 200... Loss: 1643.777466... Val Loss: 2104.324356\n",
      "Epoch: 1/100... Step: 300... Loss: 54.466068... Val Loss: 2064.624072\n",
      "Epoch: 1/100... Step: 400... Loss: 10432.914062... Val Loss: 2062.963362\n",
      "Epoch: 1/100... Step: 500... Loss: 13503.669922... Val Loss: 2078.142769\n",
      "Epoch: 1/100... Step: 600... Loss: 3507.797363... Val Loss: 2092.108017\n",
      "Epoch: 2/100... Step: 700... Loss: 763.471069... Val Loss: 2060.785263\n",
      "Epoch: 2/100... Step: 800... Loss: 169.273315... Val Loss: 2044.474991\n",
      "Epoch: 2/100... Step: 900... Loss: 57.813396... Val Loss: 2045.836126\n",
      "Epoch: 2/100... Step: 1000... Loss: 235.050858... Val Loss: 2069.093626\n",
      "Epoch: 2/100... Step: 1100... Loss: 24.897722... Val Loss: 2061.223530\n",
      "Epoch: 2/100... Step: 1200... Loss: 52971.238281... Val Loss: 2072.519910\n",
      "Epoch: 3/100... Step: 1300... Loss: 187.633240... Val Loss: 2058.185806\n",
      "Epoch: 3/100... Step: 1400... Loss: 65.699059... Val Loss: 2078.738826\n",
      "Epoch: 3/100... Step: 1500... Loss: 30144.923828... Val Loss: 2083.778056\n",
      "Epoch: 3/100... Step: 1600... Loss: 1118.702637... Val Loss: 2073.917208\n",
      "Epoch: 3/100... Step: 1700... Loss: 2211.095947... Val Loss: 2101.359330\n",
      "Epoch: 3/100... Step: 1800... Loss: 2895.232178... Val Loss: 2071.246041\n",
      "Epoch: 4/100... Step: 1900... Loss: 29635.611328... Val Loss: 2036.698870\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14292/3959857911.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m#                 print(inputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;31m#                 print(output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m                                        \"them on device: {}\".format(self.src_device_obj, t.device))\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m             \u001b[1;31m# for forward function without any inputs, empty list and dict will be created\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;31m# so the module can be executed on one device which is the first one in device_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\scatter_gather.py\u001b[0m in \u001b[0;36mscatter_kwargs\u001b[1;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;34mr\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\scatter_gather.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# None, clearing the cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mscatter_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_namedtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;31m# Perform CPU to GPU copies in a background stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mstreams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_get_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;31m# Synchronize with the copy stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstreams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\comm.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(tensor, devices, chunk_sizes, dim, streams, out)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mdevices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_get_device_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdevices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "output_size = 1\n",
    "embedding_dim = embedding_matrix.size()[1]\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "net = SentimentLSTM(output_size, embedding_matrix,embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "# loss and optimization functions\n",
    "\n",
    "\n",
    "lr=0.001\n",
    "\n",
    "ce = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# training params\n",
    "\n",
    "epochs = 100 # 9-11 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if torch.cuda.is_available():\n",
    "    net = torch.nn.DataParallel(net, device_ids=[0]).cuda()\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.module.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        labels = labels.float()\n",
    "        counter += 1\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = net(inputs, h)\n",
    "        \n",
    "        # calculate the loss and perform backprop\n",
    "        loss = ce(output, labels)\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.module.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "                labels = labels.float()\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "#                 inputs = embedding(inputs)\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "#                 print(inputs)\n",
    "                output, val_h = net(inputs, val_h)\n",
    "#                 print(output)\n",
    "                val_loss = ce(output, labels)\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3e65fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_loader):\n",
    "    # Get test data loss and accuracy\n",
    "    pred_list = []\n",
    "    true_list = []\n",
    "    test_losses = [] # track loss\n",
    "    num_correct = 0\n",
    "\n",
    "    # init hidden state\n",
    "    h = net.module.init_hidden(batch_size)\n",
    "\n",
    "    net.eval()\n",
    "    # iterate over test data\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # get predicted outputs\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate loss\n",
    "        test_loss = ce(output.squeeze(), labels.long())\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        # convert output probabilities to predicted class (0 or 1)\n",
    "#         pred = torch.max(output,1)[1]  # rounds to the nearest integer\n",
    "        pred = []\n",
    "        for i in output.tolist():\n",
    "            pred.append(i[0])\n",
    "        pred_list = pred_list + pred\n",
    "#         true_list = true_list + labels.tolist()\n",
    "        # compare predictions to true label\n",
    "#         correct_tensor = pred.eq(labels.view_as(pred))\n",
    "#         correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#         num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "#     # -- stats! -- ##\n",
    "#     # avg test loss\n",
    "#     print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "    # accuracy over all test data\n",
    "#     test_acc = num_correct/len(test_loader.dataset)\n",
    "#     print(\"Test accuracy: {:.3f}\".format(test_acc))\n",
    "    return true_list,pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "6daf64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues, preds = evaluation(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "94499c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "# data_dict = {'seman':preds}\n",
    "data_dict = {'lexical':y_pred_lexical}\n",
    "final = DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9f20f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['id'] = data['id']\n",
    "final['struc'] = y_pred['pred']\n",
    "final['true'] = data['value']\n",
    "final['lexical'] = y_pred_lexical\n",
    "final['time_id'] = data_set['time_id']\n",
    "final['struc*time'] = final['struc']*final['time_id']\n",
    "# final['seman*time'] = final['seman']*final['time_id']\n",
    "final['lexical*time'] = final['lexical']*final['time_id']\n",
    "final['struc*lexical*time'] = final['struc']*final['lexical']*final['time_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "29c3a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('D:/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fa23de88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical</th>\n",
       "      <th>struc</th>\n",
       "      <th>true</th>\n",
       "      <th>time_id</th>\n",
       "      <th>struc*time</th>\n",
       "      <th>lexical*time</th>\n",
       "      <th>struc*lexical*time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lexical</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259717</td>\n",
       "      <td>0.981961</td>\n",
       "      <td>0.006468</td>\n",
       "      <td>0.212307</td>\n",
       "      <td>0.897974</td>\n",
       "      <td>0.630828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>struc</th>\n",
       "      <td>0.259717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255041</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.812860</td>\n",
       "      <td>0.225408</td>\n",
       "      <td>0.430187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>0.981961</td>\n",
       "      <td>0.255041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.207348</td>\n",
       "      <td>0.877666</td>\n",
       "      <td>0.618570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <td>0.006468</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422319</td>\n",
       "      <td>0.119111</td>\n",
       "      <td>0.064997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>struc*time</th>\n",
       "      <td>0.212307</td>\n",
       "      <td>0.812860</td>\n",
       "      <td>0.207348</td>\n",
       "      <td>0.422319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.270212</td>\n",
       "      <td>0.449024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lexical*time</th>\n",
       "      <td>0.897974</td>\n",
       "      <td>0.225408</td>\n",
       "      <td>0.877666</td>\n",
       "      <td>0.119111</td>\n",
       "      <td>0.270212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>struc*lexical*time</th>\n",
       "      <td>0.630828</td>\n",
       "      <td>0.430187</td>\n",
       "      <td>0.618570</td>\n",
       "      <td>0.064997</td>\n",
       "      <td>0.449024</td>\n",
       "      <td>0.673891</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lexical     struc      true   time_id  struc*time  \\\n",
       "lexical             1.000000  0.259717  0.981961  0.006468    0.212307   \n",
       "struc               0.259717  1.000000  0.255041  0.006279    0.812860   \n",
       "true                0.981961  0.255041  1.000000  0.002154    0.207348   \n",
       "time_id             0.006468  0.006279  0.002154  1.000000    0.422319   \n",
       "struc*time          0.212307  0.812860  0.207348  0.422319    1.000000   \n",
       "lexical*time        0.897974  0.225408  0.877666  0.119111    0.270212   \n",
       "struc*lexical*time  0.630828  0.430187  0.618570  0.064997    0.449024   \n",
       "\n",
       "                    lexical*time  struc*lexical*time  \n",
       "lexical                 0.897974            0.630828  \n",
       "struc                   0.225408            0.430187  \n",
       "true                    0.877666            0.618570  \n",
       "time_id                 0.119111            0.064997  \n",
       "struc*time              0.270212            0.449024  \n",
       "lexical*time            1.000000            0.673891  \n",
       "struc*lexical*time      0.673891            1.000000  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "53ee1e12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.964\n",
      "Model:                            OLS   Adj. R-squared:                  0.964\n",
      "Method:                 Least Squares   F-statistic:                 2.256e+04\n",
      "Date:                Wed, 31 Aug 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:15:55   Log-Likelihood:                -17753.\n",
      "No. Observations:                5010   AIC:                         3.552e+04\n",
      "Df Residuals:                    5003   BIC:                         3.557e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.4670      0.370      1.261      0.208      -0.259       1.193\n",
      "lexical                1.0199      0.007    155.613      0.000       1.007       1.033\n",
      "struc                 -0.0290      0.024     -1.206      0.228      -0.076       0.018\n",
      "time_id               -0.0788      0.060     -1.322      0.186      -0.196       0.038\n",
      "lexical*time          -0.0036      0.001     -3.425      0.001      -0.006      -0.002\n",
      "struc*time             0.0046      0.004      1.186      0.236      -0.003       0.012\n",
      "struc*lexical*time  8.532e-06   1.56e-05      0.549      0.583    -2.2e-05     3.9e-05\n",
      "==============================================================================\n",
      "Omnibus:                     8884.583   Durbin-Watson:                   2.535\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        144305355.570\n",
      "Skew:                          11.479   Prob(JB):                         0.00\n",
      "Kurtosis:                     834.117   Cond. No.                     3.63e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.63e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X=sm.add_constant(final[['lexical','struc','time_id','lexical*time','struc*time','struc*lexical*time']]) #添加常数项\n",
    "model=sm.OLS(final['true'],X)\n",
    "results=model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "50c0f9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     1.552\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.213\n",
      "Time:                        03:18:56   Log-Likelihood:                -24393.\n",
      "No. Observations:                4600   AIC:                         4.879e+04\n",
      "Df Residuals:                    4598   BIC:                         4.880e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         96.3098     66.348      1.452      0.147     -33.764     226.384\n",
      "seman         -9.1291      7.328     -1.246      0.213     -23.496       5.238\n",
      "==============================================================================\n",
      "Omnibus:                     7086.826   Durbin-Watson:                   1.602\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2971783.213\n",
      "Skew:                           9.768   Prob(JB):                         0.00\n",
      "Kurtosis:                     125.977   Cond. No.                         848.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X=sm.add_constant(final[['seman']]) #添加常数项\n",
    "model=sm.OLS(final['true'],X)\n",
    "results=model.fit()\n",
    "y_pred2=pd.DataFrame(model.predict(results.params,X),\n",
    "                    columns=['pred'])\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8e9ff164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                 -0.002\n",
      "Method:                 Least Squares   F-statistic:                    0.6410\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.527\n",
      "Time:                        03:19:11   Log-Likelihood:                -2591.6\n",
      "No. Observations:                 458   AIC:                             5189.\n",
      "Df Residuals:                     455   BIC:                             5202.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -53.7140    351.351     -0.153      0.879    -744.187     636.759\n",
      "seman          8.3148     39.005      0.213      0.831     -68.337      84.966\n",
      "struc         -0.3117      0.279     -1.117      0.264      -0.860       0.237\n",
      "==============================================================================\n",
      "Omnibus:                      699.466   Durbin-Watson:                   1.977\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           132148.192\n",
      "Skew:                           8.484   Prob(JB):                         0.00\n",
      "Kurtosis:                      84.467   Cond. No.                     2.32e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.32e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "2\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.003\n",
      "Method:                 Least Squares   F-statistic:                     1.718\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.181\n",
      "Time:                        03:19:11   Log-Likelihood:                -2176.4\n",
      "No. Observations:                 438   AIC:                             4359.\n",
      "Df Residuals:                     435   BIC:                             4371.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        285.2918    173.591      1.643      0.101     -55.889     626.473\n",
      "seman        -30.0542     19.265     -1.560      0.119     -67.918       7.810\n",
      "struc         -0.0573      0.140     -0.408      0.684      -0.333       0.219\n",
      "==============================================================================\n",
      "Omnibus:                      498.888   Durbin-Watson:                   1.826\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22533.847\n",
      "Skew:                           5.419   Prob(JB):                         0.00\n",
      "Kurtosis:                      36.426   Cond. No.                     2.26e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.26e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "3\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                    0.7753\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.461\n",
      "Time:                        03:19:11   Log-Likelihood:                -2454.3\n",
      "No. Observations:                 471   AIC:                             4915.\n",
      "Df Residuals:                     468   BIC:                             4927.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        211.5751    208.212      1.016      0.310    -197.571     620.721\n",
      "seman        -21.7605     23.102     -0.942      0.347     -67.157      23.636\n",
      "struc         -0.0722      0.162     -0.445      0.657      -0.391       0.247\n",
      "==============================================================================\n",
      "Omnibus:                      757.585   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           230613.196\n",
      "Skew:                           9.201   Prob(JB):                         0.00\n",
      "Kurtosis:                     109.829   Cond. No.                     2.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "4\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.011\n",
      "Model:                            OLS   Adj. R-squared:                  0.007\n",
      "Method:                 Least Squares   F-statistic:                     2.722\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):             0.0668\n",
      "Time:                        03:19:11   Log-Likelihood:                -2308.3\n",
      "No. Observations:                 474   AIC:                             4623.\n",
      "Df Residuals:                     471   BIC:                             4635.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        136.3461    137.791      0.990      0.323    -134.415     407.108\n",
      "seman        -14.2825     15.281     -0.935      0.350     -44.309      15.744\n",
      "struc          0.2923      0.126      2.325      0.020       0.045       0.539\n",
      "==============================================================================\n",
      "Omnibus:                      701.507   Durbin-Watson:                   1.974\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           153605.959\n",
      "Skew:                           7.920   Prob(JB):                         0.00\n",
      "Kurtosis:                      89.756   Cond. No.                     2.02e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.02e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "5\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.003\n",
      "Method:                 Least Squares   F-statistic:                    0.2080\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.812\n",
      "Time:                        03:19:11   Log-Likelihood:                -2480.2\n",
      "No. Observations:                 461   AIC:                             4966.\n",
      "Df Residuals:                     458   BIC:                             4979.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -32.6432    216.803     -0.151      0.880    -458.696     393.410\n",
      "seman          5.2472     24.058      0.218      0.827     -42.030      52.525\n",
      "struc         -0.1428      0.221     -0.645      0.519      -0.578       0.292\n",
      "==============================================================================\n",
      "Omnibus:                      886.748   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           783915.996\n",
      "Skew:                          12.805   Prob(JB):                         0.00\n",
      "Kurtosis:                     203.388   Cond. No.                     1.86e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.86e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "6\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                    0.7991\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.450\n",
      "Time:                        03:19:11   Log-Likelihood:                -2640.3\n",
      "No. Observations:                 483   AIC:                             5287.\n",
      "Df Residuals:                     480   BIC:                             5299.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -42.0689    222.333     -0.189      0.850    -478.936     394.798\n",
      "seman          6.8740     24.695      0.278      0.781     -41.650      55.398\n",
      "struc         -0.2741      0.221     -1.241      0.215      -0.708       0.160\n",
      "==============================================================================\n",
      "Omnibus:                      769.453   Durbin-Watson:                   2.040\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           201826.793\n",
      "Skew:                           9.145   Prob(JB):                         0.00\n",
      "Kurtosis:                     101.459   Cond. No.                     1.86e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.86e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "7\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                 -0.002\n",
      "Method:                 Least Squares   F-statistic:                    0.4645\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.629\n",
      "Time:                        03:19:11   Log-Likelihood:                -2562.6\n",
      "No. Observations:                 463   AIC:                             5131.\n",
      "Df Residuals:                     460   BIC:                             5144.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         67.6345    288.918      0.234      0.815    -500.129     635.398\n",
      "seman         -5.9212     32.035     -0.185      0.853     -68.874      57.032\n",
      "struc          0.2132      0.223      0.956      0.340      -0.225       0.651\n",
      "==============================================================================\n",
      "Omnibus:                      626.809   Durbin-Watson:                   1.847\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            68263.058\n",
      "Skew:                           6.964   Prob(JB):                         0.00\n",
      "Kurtosis:                      60.832   Cond. No.                     2.25e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.25e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "8\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.003\n",
      "Method:                 Least Squares   F-statistic:                    0.2660\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.767\n",
      "Time:                        03:19:11   Log-Likelihood:                -2241.4\n",
      "No. Observations:                 439   AIC:                             4489.\n",
      "Df Residuals:                     436   BIC:                             4501.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        143.5878    211.121      0.680      0.497    -271.353     558.528\n",
      "seman        -14.6387     23.369     -0.626      0.531     -60.568      31.290\n",
      "struc          0.0681      0.130      0.523      0.601      -0.188       0.324\n",
      "==============================================================================\n",
      "Omnibus:                      645.934   Durbin-Watson:                   2.038\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           103640.788\n",
      "Skew:                           7.895   Prob(JB):                         0.00\n",
      "Kurtosis:                      76.598   Cond. No.                     2.61e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.61e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "9\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.004\n",
      "Method:                 Least Squares   F-statistic:                   0.05576\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.946\n",
      "Time:                        03:19:11   Log-Likelihood:                -2406.8\n",
      "No. Observations:                 463   AIC:                             4820.\n",
      "Df Residuals:                     460   BIC:                             4832.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -45.8041    186.511     -0.246      0.806    -412.322     320.714\n",
      "seman          6.4850     20.678      0.314      0.754     -34.150      47.120\n",
      "struc          0.0026      0.151      0.017      0.986      -0.295       0.300\n",
      "==============================================================================\n",
      "Omnibus:                      770.323   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           288899.478\n",
      "Skew:                           9.731   Prob(JB):                         0.00\n",
      "Kurtosis:                     123.816   Cond. No.                     2.07e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.07e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "10\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   true   R-squared:                       0.007\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     1.553\n",
      "Date:                Mon, 29 Aug 2022   Prob (F-statistic):              0.213\n",
      "Time:                        03:19:11   Log-Likelihood:                -2220.0\n",
      "No. Observations:                 450   AIC:                             4446.\n",
      "Df Residuals:                     447   BIC:                             4458.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        260.1617    174.911      1.487      0.138     -83.588     603.912\n",
      "seman        -27.4037     19.405     -1.412      0.159     -65.539      10.732\n",
      "struc         -0.0579      0.114     -0.505      0.614      -0.283       0.167\n",
      "==============================================================================\n",
      "Omnibus:                      773.127   Durbin-Watson:                   2.028\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           404654.788\n",
      "Skew:                          10.173   Prob(JB):                         0.00\n",
      "Kurtosis:                     148.491   Cond. No.                     2.56e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.56e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "semans = []\n",
    "strucs = []\n",
    "for i in range(1,11):\n",
    "    X=sm.add_constant(final[final['time_id']==i][['seman','struc']]) #添加常数项\n",
    "    model=sm.OLS(final[final['time_id']==i]['true'],X)\n",
    "    results=model.fit()\n",
    "    semans.append(results.params['seman'])\n",
    "    strucs.append(results.params['struc'])\n",
    "    print(i)\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bd1153e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = range(1,11)\n",
    "l1=plt.plot(x,semans,'r--',label='seman')\n",
    "l2=plt.plot(x,strucs,'g--',label='struc')\n",
    "plt.title('The change of the coef of seman and struc by time')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('coef')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "6055a209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.13616477],\n",
       "       [0.13616477, 1.        ]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(final['seman2'], final['true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c767bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
